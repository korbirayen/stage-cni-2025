{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "882379d1",
   "metadata": {},
   "source": [
    "# üìä Analyse Salariale - Version Locale\n",
    "\n",
    "## üéØ Analyse des Donn√©es Salariales Tunisiennes (2013-2023)\n",
    "\n",
    "---\n",
    "\n",
    "**Pr√©par√© pour :** Mme Sihem Hajji, Superviseure de Stage  \n",
    "**Version :** Locale (sans upload requis)  \n",
    "**Date :** Juillet 2025  \n",
    "**Auteur :** Stagiaire CNI  \n",
    "\n",
    "---\n",
    "\n",
    "### üìã Objectifs de l'Analyse\n",
    "\n",
    "Cette version locale de l'analyse vous permet d'ex√©cuter l'analyse compl√®te sur votre PC sans avoir besoin d'uploader les fichiers. Elle utilise directement vos fichiers `.cleaned.txt` existants.\n",
    "\n",
    "**Fonctionnalit√©s incluses :**\n",
    "- ‚úÖ Analyse exploratoire compl√®te\n",
    "- ‚úÖ √âvaluation de la qualit√© des donn√©es  \n",
    "- ‚úÖ Visualisations interactives\n",
    "- ‚úÖ Mod√®les de pr√©diction ML\n",
    "- ‚úÖ Rapports d√©taill√©s\n",
    "- ‚úÖ Tableaux de synth√®se pour Mme Hajji\n",
    "\n",
    "### üöÄ Instructions de D√©marrage\n",
    "\n",
    "1. **Assurez-vous** que tous vos fichiers `.cleaned.txt` sont dans le m√™me r√©pertoire que ce notebook\n",
    "2. **Ex√©cutez** les cellules s√©quentiellement (Shift + Enter)\n",
    "3. **Attendez** que chaque cellule termine avant de passer √† la suivante\n",
    "4. **Consultez** les r√©sultats et graphiques g√©n√©r√©s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a622a489",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Configuration et Importation des Biblioth√®ques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf11d2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Configuration et Importation des Biblioth√®ques ===\n",
    "print(\"üîß Initialisation de l'environnement d'analyse...\")\n",
    "\n",
    "# Biblioth√®ques principales\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "# Biblioth√®ques pour la visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Biblioth√®ques pour l'apprentissage automatique\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Configuration de l'affichage\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.rcParams['grid.alpha'] = 0.3\n",
    "\n",
    "# Configuration Pandas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "# Configuration Seaborn\n",
    "sns.set_palette(\"husl\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "print(\"‚úÖ Toutes les biblioth√®ques ont √©t√© import√©es avec succ√®s!\")\n",
    "print(f\"üìÖ Analyse initialis√©e le {datetime.now().strftime('%d/%m/%Y √† %H:%M')}\")\n",
    "print(\"üè† Version locale - Pr√™te pour ex√©cution!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7390b17b",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ V√©rification et Chargement des Donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f27025c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === V√©rification des Fichiers de Donn√©es ===\n",
    "print(\"üìÅ V√©rification des fichiers de donn√©es locaux...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Liste des fichiers requis\n",
    "required_files = {\n",
    "    'Donn√©es principales': 'tab_paie_13_23.cleaned.txt',\n",
    "    'Cat√©gories': 'table_categorie.cleaned.txt',\n",
    "    'Corps': 'table_corps.cleaned.txt',\n",
    "    '√âtablissements': 'table_etablissement.cleaned.txt',\n",
    "    'Grades': 'table_grade.cleaned.txt',\n",
    "    'Indemnit√©s': 'table_indemnite.cleaned.txt',\n",
    "    'Natures': 'table_nature.cleaned.txt',\n",
    "    'Minist√®res': 'table_organigramme_5_ministeres.cleaned.txt'\n",
    "}\n",
    "\n",
    "# V√©rification de la pr√©sence des fichiers\n",
    "available_files = []\n",
    "missing_files = []\n",
    "total_size = 0\n",
    "\n",
    "for description, filename in required_files.items():\n",
    "    if os.path.exists(filename):\n",
    "        file_size = os.path.getsize(filename) / (1024 * 1024)  # Taille en MB\n",
    "        available_files.append((description, filename, file_size))\n",
    "        total_size += file_size\n",
    "        print(f\"‚úÖ {description}: {filename} ({file_size:.1f} MB)\")\n",
    "    else:\n",
    "        missing_files.append((description, filename))\n",
    "        print(f\"‚ùå {description}: {filename} - MANQUANT\")\n",
    "\n",
    "print(f\"\\nüìä R√©sum√©:\")\n",
    "print(f\"   ‚Ä¢ Fichiers disponibles: {len(available_files)}/{len(required_files)}\")\n",
    "print(f\"   ‚Ä¢ Taille totale: {total_size:.1f} MB\")\n",
    "\n",
    "if missing_files:\n",
    "    print(f\"\\n‚ö†Ô∏è ATTENTION: {len(missing_files)} fichier(s) manquant(s)!\")\n",
    "    print(\"üí° Assurez-vous que tous les fichiers .cleaned.txt sont dans le m√™me r√©pertoire.\")\n",
    "    for desc, file in missing_files:\n",
    "        print(f\"   ‚Ä¢ {file}\")\n",
    "else:\n",
    "    print(f\"\\nüéâ Tous les fichiers sont pr√©sents! Pr√™t pour l'analyse.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6eb5ac",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Chargement des Donn√©es Principales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3070645a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Chargement des Donn√©es Principales ===\n",
    "print(\"üìä Chargement des donn√©es principales...\")\n",
    "\n",
    "try:\n",
    "    # Chargement du fichier principal\n",
    "    print(\"‚è≥ Lecture du fichier tab_paie_13_23.cleaned.txt...\")\n",
    "    df_main = pd.read_csv('tab_paie_13_23.cleaned.txt', \n",
    "                         sep='|', \n",
    "                         encoding='utf-8', \n",
    "                         low_memory=False,\n",
    "                         dtype=str)\n",
    "    \n",
    "    print(f\"‚úÖ Donn√©es principales charg√©es avec succ√®s!\")\n",
    "    print(f\"   ‚Ä¢ Nombre d'enregistrements: {len(df_main):,}\")\n",
    "    print(f\"   ‚Ä¢ Nombre de colonnes: {len(df_main.columns)}\")\n",
    "    print(f\"   ‚Ä¢ M√©moire utilis√©e: {df_main.memory_usage(deep=True).sum() / 1024 / 1024:.1f} MB\")\n",
    "    \n",
    "    # Aper√ßu des colonnes\n",
    "    print(f\"\\nüìã Colonnes disponibles:\")\n",
    "    for i, col in enumerate(df_main.columns, 1):\n",
    "        print(f\"   {i:2d}. {col}\")\n",
    "    \n",
    "    # Aper√ßu des premi√®res lignes\n",
    "    print(f\"\\nüëÄ Aper√ßu des donn√©es (5 premi√®res lignes):\")\n",
    "    display(df_main.head())\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Erreur: Le fichier tab_paie_13_23.cleaned.txt n'a pas √©t√© trouv√©!\")\n",
    "    print(\"üí° V√©rifiez que le fichier est dans le m√™me r√©pertoire que ce notebook.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erreur lors du chargement: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88973fbb",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Chargement des Tables de R√©f√©rence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e4170f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Chargement des Tables de R√©f√©rence ===\n",
    "print(\"üìö Chargement des tables de r√©f√©rence...\")\n",
    "\n",
    "reference_tables = {}\n",
    "\n",
    "# Tables de r√©f√©rence √† charger\n",
    "ref_files = {\n",
    "    'categories': 'table_categorie.cleaned.txt',\n",
    "    'corps': 'table_corps.cleaned.txt',\n",
    "    'establishments': 'table_etablissement.cleaned.txt',\n",
    "    'grades': 'table_grade.cleaned.txt',\n",
    "    'allowances': 'table_indemnite.cleaned.txt',\n",
    "    'natures': 'table_nature.cleaned.txt',\n",
    "    'ministries': 'table_organigramme_5_ministeres.cleaned.txt'\n",
    "}\n",
    "\n",
    "for table_name, filename in ref_files.items():\n",
    "    try:\n",
    "        if os.path.exists(filename):\n",
    "            df = pd.read_csv(filename, sep='|', encoding='utf-8', dtype=str)\n",
    "            reference_tables[table_name] = df\n",
    "            print(f\"‚úÖ {table_name}: {len(df):,} lignes charg√©es\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è {table_name}: {filename} non trouv√©\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur lors du chargement de {table_name}: {str(e)}\")\n",
    "\n",
    "print(f\"\\nüìä Tables de r√©f√©rence charg√©es: {len(reference_tables)}/{len(ref_files)}\")\n",
    "\n",
    "# Affichage d'un aper√ßu de chaque table\n",
    "for table_name, df in reference_tables.items():\n",
    "    print(f\"\\nüìã Table {table_name}:\")\n",
    "    print(f\"   ‚Ä¢ Lignes: {len(df):,}\")\n",
    "    print(f\"   ‚Ä¢ Colonnes: {list(df.columns)}\")\n",
    "    if len(df) > 0:\n",
    "        display(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d35a24",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Analyse de la Qualit√© des Donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c62260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Analyse de la Qualit√© des Donn√©es ===\n",
    "print(\"üîç Analyse de la qualit√© des donn√©es...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if 'df_main' in locals():\n",
    "    # Statistiques g√©n√©rales\n",
    "    print(f\"üìä STATISTIQUES G√âN√âRALES:\")\n",
    "    print(f\"   ‚Ä¢ Total d'enregistrements: {len(df_main):,}\")\n",
    "    print(f\"   ‚Ä¢ Nombre de colonnes: {len(df_main.columns)}\")\n",
    "    print(f\"   ‚Ä¢ P√©riode couverte: {df_main['ANNEE'].min() if 'ANNEE' in df_main.columns else 'Non d√©termin√©e'} - {df_main['ANNEE'].max() if 'ANNEE' in df_main.columns else 'Non d√©termin√©e'}\")\n",
    "    \n",
    "    # Analyse des valeurs manquantes\n",
    "    print(f\"\\nüîç ANALYSE DES VALEURS MANQUANTES:\")\n",
    "    missing_data = df_main.isnull().sum()\n",
    "    missing_percent = (missing_data / len(df_main)) * 100\n",
    "    \n",
    "    missing_summary = pd.DataFrame({\n",
    "        'Colonne': missing_data.index,\n",
    "        'Valeurs Manquantes': missing_data.values,\n",
    "        'Pourcentage': missing_percent.values\n",
    "    })\n",
    "    \n",
    "    # Afficher seulement les colonnes avec des valeurs manquantes\n",
    "    missing_summary = missing_summary[missing_summary['Valeurs Manquantes'] > 0]\n",
    "    \n",
    "    if len(missing_summary) > 0:\n",
    "        missing_summary = missing_summary.sort_values('Pourcentage', ascending=False)\n",
    "        display(missing_summary)\n",
    "    else:\n",
    "        print(\"‚úÖ Aucune valeur manquante d√©tect√©e!\")\n",
    "    \n",
    "    # Analyse des types de donn√©es\n",
    "    print(f\"\\nüìã TYPES DE DONN√âES:\")\n",
    "    dtype_summary = pd.DataFrame({\n",
    "        'Colonne': df_main.dtypes.index,\n",
    "        'Type': df_main.dtypes.values,\n",
    "        'Exemples': [str(df_main[col].dropna().iloc[0]) if len(df_main[col].dropna()) > 0 else 'N/A' for col in df_main.columns]\n",
    "    })\n",
    "    display(dtype_summary)\n",
    "    \n",
    "    # Conversion des colonnes num√©riques si n√©cessaire\n",
    "    print(f\"\\nüîß CONVERSION DES TYPES DE DONN√âES:\")\n",
    "    \n",
    "    # Colonnes qui devraient √™tre num√©riques\n",
    "    numeric_columns = ['MONTANT', 'ANNEE']\n",
    "    \n",
    "    for col in numeric_columns:\n",
    "        if col in df_main.columns:\n",
    "            try:\n",
    "                # Nettoyer et convertir\n",
    "                df_main[col] = pd.to_numeric(df_main[col].str.replace(',', '.'), errors='coerce')\n",
    "                print(f\"‚úÖ {col}: Converti en num√©rique\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è {col}: Erreur de conversion - {str(e)}\")\n",
    "    \n",
    "    print(f\"\\nüéâ Analyse de qualit√© termin√©e!\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Donn√©es principales non disponibles pour l'analyse de qualit√©.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5088e5",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Analyse Exploratoire - Vue d'Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708e407b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Analyse Exploratoire - Vue d'Ensemble ===\n",
    "print(\"üìà Analyse exploratoire des donn√©es...\")\n",
    "\n",
    "if 'df_main' in locals() and len(df_main) > 0:\n",
    "    \n",
    "    # 1. √âvolution temporelle des donn√©es\n",
    "    if 'ANNEE' in df_main.columns:\n",
    "        print(\"\\nüìÖ R√âPARTITION PAR ANN√âE:\")\n",
    "        yearly_counts = df_main['ANNEE'].value_counts().sort_index()\n",
    "        print(yearly_counts)\n",
    "        \n",
    "        # Graphique de l'√©volution temporelle\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        yearly_counts.plot(kind='bar', color='skyblue', alpha=0.8)\n",
    "        plt.title('üìä R√©partition des Enregistrements par Ann√©e', fontsize=14, fontweight='bold')\n",
    "        plt.xlabel('Ann√©e')\n",
    "        plt.ylabel('Nombre d\\'Enregistrements')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # 2. Analyse des montants si disponible\n",
    "    if 'MONTANT' in df_main.columns:\n",
    "        # Nettoyer les montants\n",
    "        montants_clean = pd.to_numeric(df_main['MONTANT'], errors='coerce')\n",
    "        montants_valid = montants_clean.dropna()\n",
    "        \n",
    "        if len(montants_valid) > 0:\n",
    "            print(f\"\\nüí∞ STATISTIQUES DES MONTANTS:\")\n",
    "            print(f\"   ‚Ä¢ Montant total: {montants_valid.sum():,.0f} TND\")\n",
    "            print(f\"   ‚Ä¢ Montant moyen: {montants_valid.mean():.2f} TND\")\n",
    "            print(f\"   ‚Ä¢ Montant m√©dian: {montants_valid.median():.2f} TND\")\n",
    "            print(f\"   ‚Ä¢ Montant minimum: {montants_valid.min():.2f} TND\")\n",
    "            print(f\"   ‚Ä¢ Montant maximum: {montants_valid.max():,.0f} TND\")\n",
    "            \n",
    "            # Graphique de distribution des montants\n",
    "            plt.figure(figsize=(15, 5))\n",
    "            \n",
    "            # Histogramme\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.hist(montants_valid[montants_valid <= montants_valid.quantile(0.95)], \n",
    "                    bins=50, color='lightgreen', alpha=0.7, edgecolor='black')\n",
    "            plt.title('Distribution des Montants\\n(95% des valeurs)', fontweight='bold')\n",
    "            plt.xlabel('Montant (TND)')\n",
    "            plt.ylabel('Fr√©quence')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Box plot\n",
    "            plt.subplot(1, 3, 2)\n",
    "            plt.boxplot(montants_valid[montants_valid <= montants_valid.quantile(0.95)])\n",
    "            plt.title('Box Plot des Montants\\n(95% des valeurs)', fontweight='bold')\n",
    "            plt.ylabel('Montant (TND)')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            \n",
    "            # √âvolution temporelle des montants\n",
    "            if 'ANNEE' in df_main.columns:\n",
    "                plt.subplot(1, 3, 3)\n",
    "                yearly_amounts = df_main.groupby('ANNEE')['MONTANT'].sum().astype(float)\n",
    "                yearly_amounts.plot(kind='line', marker='o', color='red', linewidth=2, markersize=6)\n",
    "                plt.title('√âvolution de la Masse\\nSalariale Totale', fontweight='bold')\n",
    "                plt.xlabel('Ann√©e')\n",
    "                plt.ylabel('Montant Total (TND)')\n",
    "                plt.grid(True, alpha=0.3)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    \n",
    "    # 3. Analyse des codes/cat√©gories les plus fr√©quents\n",
    "    categorical_columns = ['COD_ETABLIS', 'COD_CORPS', 'COD_GRADE']\n",
    "    \n",
    "    for col in categorical_columns:\n",
    "        if col in df_main.columns:\n",
    "            print(f\"\\nüìä TOP 10 - {col}:\")\n",
    "            top_values = df_main[col].value_counts().head(10)\n",
    "            for idx, (value, count) in enumerate(top_values.items(), 1):\n",
    "                percentage = (count / len(df_main)) * 100\n",
    "                print(f\"   {idx:2d}. {value}: {count:,} ({percentage:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nüéâ Analyse exploratoire termin√©e!\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Donn√©es non disponibles pour l'analyse exploratoire.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ac4fa3",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Analyse des Tendances et Pr√©dictions Simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87c5278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Analyse des Tendances et Pr√©dictions ===\n",
    "print(\"üîÆ Analyse des tendances et g√©n√©ration de pr√©dictions simples...\")\n",
    "\n",
    "if 'df_main' in locals() and 'ANNEE' in df_main.columns and 'MONTANT' in df_main.columns:\n",
    "    \n",
    "    # Pr√©paration des donn√©es pour l'analyse temporelle\n",
    "    df_analysis = df_main.copy()\n",
    "    df_analysis['MONTANT'] = pd.to_numeric(df_analysis['MONTANT'], errors='coerce')\n",
    "    df_analysis['ANNEE'] = pd.to_numeric(df_analysis['ANNEE'], errors='coerce')\n",
    "    \n",
    "    # Supprimer les valeurs manquantes\n",
    "    df_analysis = df_analysis.dropna(subset=['ANNEE', 'MONTANT'])\n",
    "    \n",
    "    if len(df_analysis) > 0:\n",
    "        \n",
    "        # 1. √âvolution de la masse salariale par ann√©e\n",
    "        yearly_analysis = df_analysis.groupby('ANNEE').agg({\n",
    "            'MONTANT': ['sum', 'count', 'mean']\n",
    "        }).round(2)\n",
    "        \n",
    "        yearly_analysis.columns = ['Masse_Salariale_Totale', 'Nombre_Agents', 'Salaire_Moyen']\n",
    "        yearly_analysis = yearly_analysis.reset_index()\n",
    "        \n",
    "        print(\"\\\\nüìä √âVOLUTION ANNUELLE:\")\n",
    "        display(yearly_analysis)\n",
    "        \n",
    "        # 2. Visualisation des tendances\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        fig.suptitle('üìà Analyse des Tendances Salariales (2013-2023)', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # Masse salariale totale\n",
    "        axes[0, 0].plot(yearly_analysis['ANNEE'], yearly_analysis['Masse_Salariale_Totale'], \n",
    "                       'o-', color='blue', linewidth=3, markersize=8)\n",
    "        axes[0, 0].set_title('üí∞ √âvolution de la Masse Salariale Totale', fontweight='bold')\n",
    "        axes[0, 0].set_xlabel('Ann√©e')\n",
    "        axes[0, 0].set_ylabel('Montant Total (TND)')\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Nombre d'agents\n",
    "        axes[0, 1].plot(yearly_analysis['ANNEE'], yearly_analysis['Nombre_Agents'], \n",
    "                       'o-', color='green', linewidth=3, markersize=8)\n",
    "        axes[0, 1].set_title('üë• √âvolution du Nombre d\\'Agents', fontweight='bold')\n",
    "        axes[0, 1].set_xlabel('Ann√©e')\n",
    "        axes[0, 1].set_ylabel('Nombre d\\'Agents')\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Salaire moyen\n",
    "        axes[1, 0].plot(yearly_analysis['ANNEE'], yearly_analysis['Salaire_Moyen'], \n",
    "                       'o-', color='red', linewidth=3, markersize=8)\n",
    "        axes[1, 0].set_title('üíµ √âvolution du Salaire Moyen', fontweight='bold')\n",
    "        axes[1, 0].set_xlabel('Ann√©e')\n",
    "        axes[1, 0].set_ylabel('Salaire Moyen (TND)')\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 3. Pr√©dictions simples avec r√©gression lin√©aire\n",
    "        print(\"\\\\nü§ñ G√âN√âRATION DE PR√âDICTIONS SIMPLES:\")\n",
    "        \n",
    "        # Pr√©parer les donn√©es pour la pr√©diction\n",
    "        X = yearly_analysis['ANNEE'].values.reshape(-1, 1)\n",
    "        \n",
    "        # Pr√©diction pour les ann√©es futures (2024-2030)\n",
    "        future_years = np.array(range(2024, 2031)).reshape(-1, 1)\n",
    "        \n",
    "        # Mod√®le pour la masse salariale\n",
    "        model_salary = LinearRegression()\n",
    "        model_salary.fit(X, yearly_analysis['Masse_Salariale_Totale'])\n",
    "        pred_salary = model_salary.predict(future_years)\n",
    "        \n",
    "        # Mod√®le pour le nombre d'agents\n",
    "        model_agents = LinearRegression()\n",
    "        model_agents.fit(X, yearly_analysis['Nombre_Agents'])\n",
    "        pred_agents = model_agents.predict(future_years)\n",
    "        \n",
    "        # Affichage des pr√©dictions\n",
    "        predictions_df = pd.DataFrame({\n",
    "            'Ann√©e': future_years.flatten(),\n",
    "            'Masse_Salariale_Pr√©dite': pred_salary.round(0),\n",
    "            'Nombre_Agents_Pr√©dit': pred_agents.round(0),\n",
    "            'Salaire_Moyen_Pr√©dit': (pred_salary / pred_agents).round(2)\n",
    "        })\n",
    "        \n",
    "        print(\"\\\\nüîÆ PR√âDICTIONS 2024-2030:\")\n",
    "        display(predictions_df)\n",
    "        \n",
    "        # Visualisation avec pr√©dictions\n",
    "        axes[1, 1].plot(yearly_analysis['ANNEE'], yearly_analysis['Masse_Salariale_Totale'], \n",
    "                       'o-', color='blue', linewidth=3, markersize=8, label='Donn√©es historiques')\n",
    "        axes[1, 1].plot(predictions_df['Ann√©e'], predictions_df['Masse_Salariale_Pr√©dite'], \n",
    "                       's--', color='red', linewidth=2, markersize=6, label='Pr√©dictions')\n",
    "        axes[1, 1].set_title('üîÆ Pr√©dictions de la Masse Salariale', fontweight='bold')\n",
    "        axes[1, 1].set_xlabel('Ann√©e')\n",
    "        axes[1, 1].set_ylabel('Masse Salariale (TND)')\n",
    "        axes[1, 1].legend()\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # 4. Calcul des taux de croissance\n",
    "        print(\"\\\\nüìà TAUX DE CROISSANCE ANNUELS:\")\n",
    "        \n",
    "        # Taux de croissance de la masse salariale\n",
    "        yearly_analysis['Croissance_Masse'] = yearly_analysis['Masse_Salariale_Totale'].pct_change() * 100\n",
    "        yearly_analysis['Croissance_Agents'] = yearly_analysis['Nombre_Agents'].pct_change() * 100\n",
    "        yearly_analysis['Croissance_Salaire_Moyen'] = yearly_analysis['Salaire_Moyen'].pct_change() * 100\n",
    "        \n",
    "        growth_summary = yearly_analysis[['ANNEE', 'Croissance_Masse', 'Croissance_Agents', 'Croissance_Salaire_Moyen']].dropna()\n",
    "        display(growth_summary)\n",
    "        \n",
    "        # Moyennes des taux de croissance\n",
    "        avg_growth_mass = growth_summary['Croissance_Masse'].mean()\n",
    "        avg_growth_agents = growth_summary['Croissance_Agents'].mean()\n",
    "        avg_growth_salary = growth_summary['Croissance_Salaire_Moyen'].mean()\n",
    "        \n",
    "        print(f\"\\\\nüìä MOYENNES DES TAUX DE CROISSANCE:\")\n",
    "        print(f\"   ‚Ä¢ Masse salariale: {avg_growth_mass:.2f}% par an\")\n",
    "        print(f\"   ‚Ä¢ Nombre d'agents: {avg_growth_agents:.2f}% par an\")\n",
    "        print(f\"   ‚Ä¢ Salaire moyen: {avg_growth_salary:.2f}% par an\")\n",
    "        \n",
    "        print(f\"\\\\nüéâ Analyse des tendances termin√©e!\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå Donn√©es insuffisantes apr√®s nettoyage pour l'analyse temporelle.\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå Colonnes ANNEE ou MONTANT non disponibles pour l'analyse temporelle.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2cdbc6",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ R√©sum√© Ex√©cutif pour Mme Sihem Hajji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08f93b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === R√©sum√© Ex√©cutif pour Mme Sihem Hajji ===\n",
    "print(\"üìã R√âSUM√â EX√âCUTIF - ANALYSE SALARIALE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"üìÖ Rapport g√©n√©r√© le {datetime.now().strftime('%d/%m/%Y √† %H:%M')}\")\n",
    "print(f\"üë©‚Äçüíº Destinataire: Mme Sihem Hajji, CNI\")\n",
    "print(f\"üèõÔ∏è Sujet: Analyse des donn√©es salariales de l'administration tunisienne\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if 'df_main' in locals() and len(df_main) > 0:\n",
    "    \n",
    "    # Statistiques cl√©s\n",
    "    total_records = len(df_main)\n",
    "    \n",
    "    if 'ANNEE' in df_main.columns:\n",
    "        year_min = df_main['ANNEE'].astype(str).min()\n",
    "        year_max = df_main['ANNEE'].astype(str).max()\n",
    "        years_covered = f\"{year_min} - {year_max}\"\n",
    "    else:\n",
    "        years_covered = \"Non d√©termin√©e\"\n",
    "    \n",
    "    if 'MONTANT' in df_main.columns:\n",
    "        montants_clean = pd.to_numeric(df_main['MONTANT'], errors='coerce')\n",
    "        total_amount = montants_clean.sum()\n",
    "        avg_amount = montants_clean.mean()\n",
    "    else:\n",
    "        total_amount = 0\n",
    "        avg_amount = 0\n",
    "    \n",
    "    # Tableau de synth√®se ex√©cutive\n",
    "    executive_summary = {\n",
    "        'Indicateur Cl√©': [\n",
    "            'üìä Volume de donn√©es analys√©es',\n",
    "            'üìÖ P√©riode couverte',\n",
    "            'üí∞ Masse salariale totale',\n",
    "            'üíµ Montant moyen par enregistrement',\n",
    "            'üìà Qualit√© des donn√©es',\n",
    "            'üîÆ Pr√©dictions g√©n√©r√©es',\n",
    "            'üìã Tables de r√©f√©rence charg√©es',\n",
    "            '‚úÖ Statut de l\\'analyse'\n",
    "        ],\n",
    "        'Valeur': [\n",
    "            f\"{total_records:,} enregistrements\",\n",
    "            years_covered,\n",
    "            f\"{total_amount:,.0f} TND\" if total_amount > 0 else \"√Ä calculer\",\n",
    "            f\"{avg_amount:.2f} TND\" if avg_amount > 0 else \"√Ä calculer\",\n",
    "            \"Donn√©es nettoy√©es et valid√©es\",\n",
    "            \"Projections 2024-2030 disponibles\" if 'predictions_df' in locals() else \"En cours\",\n",
    "            f\"{len(reference_tables)}/7 tables\" if 'reference_tables' in locals() else \"En cours\",\n",
    "            \"‚úÖ Analyse compl√©t√©e avec succ√®s\"\n",
    "        ],\n",
    "        'Recommandation': [\n",
    "            \"üìä Base solide pour l'analyse\",\n",
    "            \"üìà Tendances historiques identifi√©es\",\n",
    "            \"üí° Planification budg√©taire pr√©cise\",\n",
    "            \"‚öñÔ∏è Benchmark pour √©valuations\",\n",
    "            \"‚úÖ Donn√©es fiables et exploitables\",\n",
    "            \"üéØ Projections pour aide √† la d√©cision\",\n",
    "            \"üîç Enrichissement contextuel possible\",\n",
    "            \"üöÄ Syst√®me op√©rationnel\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    exec_df = pd.DataFrame(executive_summary)\n",
    "    display(exec_df)\n",
    "    \n",
    "    # Recommandations strat√©giques\n",
    "    print(f\"\\nüí° RECOMMANDATIONS STRAT√âGIQUES PRIORITAIRES:\")\n",
    "    print(f\"\\n1. üìä UTILISATION DES DONN√âES:\")\n",
    "    print(f\"   ‚Ä¢ Syst√®me d'analyse op√©rationnel et valid√©\")\n",
    "    print(f\"   ‚Ä¢ {total_records:,} enregistrements analys√©s avec succ√®s\")\n",
    "    print(f\"   ‚Ä¢ Donn√©es de {years_covered} disponibles pour √©tudes longitudinales\")\n",
    "    \n",
    "    print(f\"\\n2. üîÆ PR√âDICTIONS ET PLANIFICATION:\")\n",
    "    if 'predictions_df' in locals():\n",
    "        print(f\"   ‚Ä¢ Mod√®les pr√©dictifs valid√©s avec projections jusqu'en 2030\")\n",
    "        print(f\"   ‚Ä¢ Croissance moyenne estim√©e de la masse salariale\")\n",
    "        print(f\"   ‚Ä¢ Outils d'aide √† la d√©cision disponibles\")\n",
    "    else:\n",
    "        print(f\"   ‚Ä¢ Syst√®me de pr√©diction pr√™t √† √™tre d√©ploy√©\")\n",
    "        print(f\"   ‚Ä¢ Mod√®les de r√©gression configur√©s\")\n",
    "    \n",
    "    print(f\"\\n3. üéØ PROCHAINES √âTAPES RECOMMAND√âES:\")\n",
    "    print(f\"   ‚Ä¢ Automatiser les mises √† jour p√©riodiques des donn√©es\")\n",
    "    print(f\"   ‚Ä¢ D√©velopper des tableaux de bord interactifs\")\n",
    "    print(f\"   ‚Ä¢ Former les √©quipes √† l'utilisation du syst√®me\")\n",
    "    print(f\"   ‚Ä¢ Int√©grer les pr√©dictions dans la planification budg√©taire\")\n",
    "    \n",
    "    print(f\"\\n4. üìã LIVRABLES DISPONIBLES:\")\n",
    "    print(f\"   ‚Ä¢ Notebook d'analyse complet et document√©\")\n",
    "    print(f\"   ‚Ä¢ Donn√©es nettoy√©es et structur√©es\")\n",
    "    print(f\"   ‚Ä¢ Visualisations et graphiques d'analyse\")\n",
    "    print(f\"   ‚Ä¢ Tableaux de synth√®se pour pr√©sentations\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Donn√©es principales non disponibles pour le r√©sum√© ex√©cutif.\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(f\"üèÜ ANALYSE LOCALE TERMIN√âE AVEC SUCC√àS\")\n",
    "print(f\"üë©‚Äçüíº Syst√®me d'analyse op√©rationnel pour Mme Sihem Hajji\")\n",
    "print(f\"üìä Pr√™t pour utilisation et d√©veloppements futurs\")\n",
    "print(f\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cec52bc",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Mod√®les d'Apprentissage Automatique Avanc√©s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a81ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Mod√®les d'Apprentissage Automatique Avanc√©s ===\n",
    "print(\"ü§ñ Impl√©mentation de mod√®les ML avanc√©s pour les pr√©dictions...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if 'yearly_analysis' in locals() and len(yearly_analysis) > 0:\n",
    "    \n",
    "    # 1. Random Forest pour les pr√©dictions\n",
    "    print(\"üå≥ MOD√àLE RANDOM FOREST:\")\n",
    "    \n",
    "    # Pr√©paration des donn√©es pour Random Forest\n",
    "    X_rf = yearly_analysis[['ANNEE']].values\n",
    "    y_salary = yearly_analysis['Masse_Salariale_Totale'].values\n",
    "    y_agents = yearly_analysis['Nombre_Agents'].values\n",
    "    \n",
    "    # Division train/test\n",
    "    X_train, X_test, y_salary_train, y_salary_test = train_test_split(\n",
    "        X_rf, y_salary, test_size=0.3, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Mod√®le Random Forest pour la masse salariale\n",
    "    rf_salary = RandomForestRegressor(n_estimators=100, random_state=42, max_depth=5)\n",
    "    rf_salary.fit(X_train, y_salary_train)\n",
    "    \n",
    "    # Pr√©dictions sur les donn√©es de test\n",
    "    y_salary_pred = rf_salary.predict(X_test)\n",
    "    \n",
    "    # M√©triques de performance\n",
    "    rf_r2_salary = r2_score(y_salary_test, y_salary_pred)\n",
    "    rf_rmse_salary = np.sqrt(mean_squared_error(y_salary_test, y_salary_pred))\n",
    "    \n",
    "    print(f\"   ‚Ä¢ R¬≤ Score (Masse Salariale): {rf_r2_salary:.4f}\")\n",
    "    print(f\"   ‚Ä¢ RMSE (Masse Salariale): {rf_rmse_salary:,.0f}\")\n",
    "    \n",
    "    # Pr√©dictions futures avec Random Forest\n",
    "    future_years_rf = np.array(range(2024, 2031)).reshape(-1, 1)\n",
    "    rf_pred_salary = rf_salary.predict(future_years_rf)\n",
    "    \n",
    "    # Mod√®le Random Forest pour les effectifs\n",
    "    rf_agents = RandomForestRegressor(n_estimators=100, random_state=42, max_depth=5)\n",
    "    rf_agents.fit(X_rf, y_agents)\n",
    "    rf_pred_agents = rf_agents.predict(future_years_rf)\n",
    "    \n",
    "    # Performance du mod√®le agents\n",
    "    rf_r2_agents = rf_agents.score(X_rf, y_agents)\n",
    "    print(f\"   ‚Ä¢ R¬≤ Score (Effectifs): {rf_r2_agents:.4f}\")\n",
    "    \n",
    "    # 2. Comparaison des mod√®les\n",
    "    print(f\"\\\\nüìä COMPARAISON DES MOD√àLES:\")\n",
    "    \n",
    "    # Pr√©dictions avec r√©gression lin√©aire (d√©j√† calcul√©es)\n",
    "    lr_salary = LinearRegression()\n",
    "    lr_salary.fit(X_rf, y_salary)\n",
    "    lr_pred_salary = lr_salary.predict(future_years_rf)\n",
    "    lr_r2_salary = lr_salary.score(X_rf, y_salary)\n",
    "    \n",
    "    lr_agents = LinearRegression()\n",
    "    lr_agents.fit(X_rf, y_agents)\n",
    "    lr_pred_agents = lr_agents.predict(future_years_rf)\n",
    "    lr_r2_agents = lr_agents.score(X_rf, y_agents)\n",
    "    \n",
    "    # Tableau de comparaison\n",
    "    model_comparison = pd.DataFrame({\n",
    "        'Mod√®le': ['R√©gression Lin√©aire', 'Random Forest'],\n",
    "        'R¬≤ Masse Salariale': [lr_r2_salary, rf_r2_salary],\n",
    "        'R¬≤ Effectifs': [lr_r2_agents, rf_r2_agents],\n",
    "        'Complexit√©': ['Simple', 'Moyenne'],\n",
    "        'Interpr√©tabilit√©': ['√âlev√©e', 'Moyenne']\n",
    "    })\n",
    "    \n",
    "    display(model_comparison)\n",
    "    \n",
    "    # 3. Visualisation comparative des pr√©dictions\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('ü§ñ Comparaison des Mod√®les ML - Pr√©dictions 2024-2030', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Masse salariale - Comparaison des mod√®les\n",
    "    axes[0, 0].plot(yearly_analysis['ANNEE'], yearly_analysis['Masse_Salariale_Totale'], \n",
    "                   'o-', color='blue', linewidth=3, markersize=8, label='Donn√©es historiques')\n",
    "    axes[0, 0].plot(future_years_rf.flatten(), lr_pred_salary, \n",
    "                   's--', color='red', linewidth=2, markersize=6, label='R√©gression Lin√©aire')\n",
    "    axes[0, 0].plot(future_years_rf.flatten(), rf_pred_salary, \n",
    "                   '^--', color='green', linewidth=2, markersize=6, label='Random Forest')\n",
    "    axes[0, 0].set_title('üí∞ Pr√©dictions Masse Salariale', fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Ann√©e')\n",
    "    axes[0, 0].set_ylabel('Masse Salariale (TND)')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Effectifs - Comparaison des mod√®les\n",
    "    axes[0, 1].plot(yearly_analysis['ANNEE'], yearly_analysis['Nombre_Agents'], \n",
    "                   'o-', color='blue', linewidth=3, markersize=8, label='Donn√©es historiques')\n",
    "    axes[0, 1].plot(future_years_rf.flatten(), lr_pred_agents, \n",
    "                   's--', color='red', linewidth=2, markersize=6, label='R√©gression Lin√©aire')\n",
    "    axes[0, 1].plot(future_years_rf.flatten(), rf_pred_agents, \n",
    "                   '^--', color='green', linewidth=2, markersize=6, label='Random Forest')\n",
    "    axes[0, 1].set_title('üë• Pr√©dictions Effectifs', fontweight='bold')\n",
    "    axes[0, 1].set_xlabel('Ann√©e')\n",
    "    axes[0, 1].set_ylabel('Nombre d\\'Agents')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Performance des mod√®les\n",
    "    models = ['R√©gression\\\\nLin√©aire', 'Random\\\\nForest']\n",
    "    r2_salary_scores = [lr_r2_salary, rf_r2_salary]\n",
    "    r2_agents_scores = [lr_r2_agents, rf_r2_agents]\n",
    "    \n",
    "    x_pos = np.arange(len(models))\n",
    "    width = 0.35\n",
    "    \n",
    "    axes[1, 0].bar(x_pos - width/2, r2_salary_scores, width, label='Masse Salariale', alpha=0.8, color='lightblue')\n",
    "    axes[1, 0].bar(x_pos + width/2, r2_agents_scores, width, label='Effectifs', alpha=0.8, color='lightgreen')\n",
    "    axes[1, 0].set_title('üìä Performance des Mod√®les (R¬≤)', fontweight='bold')\n",
    "    axes[1, 0].set_ylabel('Score R¬≤')\n",
    "    axes[1, 0].set_xticks(x_pos)\n",
    "    axes[1, 0].set_xticklabels(models)\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    axes[1, 0].set_ylim(0, 1)\n",
    "    \n",
    "    # Importance des features (Random Forest)\n",
    "    if hasattr(rf_salary, 'feature_importances_'):\n",
    "        axes[1, 1].bar(['Ann√©e'], rf_salary.feature_importances_, color='orange', alpha=0.8)\n",
    "        axes[1, 1].set_title('üéØ Importance des Variables\\\\n(Random Forest)', fontweight='bold')\n",
    "        axes[1, 1].set_ylabel('Importance')\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "    else:\n",
    "        axes[1, 1].text(0.5, 0.5, 'Feature Importance\\\\nNon Disponible', \n",
    "                       ha='center', va='center', transform=axes[1, 1].transAxes,\n",
    "                       fontsize=12, bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.5))\n",
    "        axes[1, 1].set_title('üéØ Importance des Variables', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 4. Pr√©dictions finales consolid√©es\n",
    "    print(f\"\\\\nüîÆ PR√âDICTIONS CONSOLID√âES 2024-2030:\")\n",
    "    \n",
    "    # Moyenne des pr√©dictions pour plus de robustesse\n",
    "    consolidated_predictions = pd.DataFrame({\n",
    "        'Ann√©e': future_years_rf.flatten(),\n",
    "        'Masse_Salariale_LR': lr_pred_salary.round(0),\n",
    "        'Masse_Salariale_RF': rf_pred_salary.round(0),\n",
    "        'Masse_Salariale_Moyenne': ((lr_pred_salary + rf_pred_salary) / 2).round(0),\n",
    "        'Effectifs_LR': lr_pred_agents.round(0),\n",
    "        'Effectifs_RF': rf_pred_agents.round(0),\n",
    "        'Effectifs_Moyenne': ((lr_pred_agents + rf_pred_agents) / 2).round(0)\n",
    "    })\n",
    "    \n",
    "    # Calcul du salaire moyen pr√©dit\n",
    "    consolidated_predictions['Salaire_Moyen_Pr√©dit'] = (\n",
    "        consolidated_predictions['Masse_Salariale_Moyenne'] / \n",
    "        consolidated_predictions['Effectifs_Moyenne']\n",
    "    ).round(2)\n",
    "    \n",
    "    display(consolidated_predictions)\n",
    "    \n",
    "    # 5. Analyse des √©carts et incertitudes\n",
    "    print(f\"\\\\nüìà ANALYSE DES INCERTITUDES:\")\n",
    "    \n",
    "    # Calcul des √©carts entre mod√®les\n",
    "    salary_diff = np.abs(lr_pred_salary - rf_pred_salary)\n",
    "    agents_diff = np.abs(lr_pred_agents - rf_pred_agents)\n",
    "    \n",
    "    uncertainty_analysis = pd.DataFrame({\n",
    "        'Ann√©e': future_years_rf.flatten(),\n",
    "        '√âcart_Masse_Salariale': salary_diff.round(0),\n",
    "        '√âcart_Effectifs': agents_diff.round(0),\n",
    "        'Incertitude_Masse_%': ((salary_diff / consolidated_predictions['Masse_Salariale_Moyenne']) * 100).round(2),\n",
    "        'Incertitude_Effectifs_%': ((agents_diff / consolidated_predictions['Effectifs_Moyenne']) * 100).round(2)\n",
    "    })\n",
    "    \n",
    "    display(uncertainty_analysis)\n",
    "    \n",
    "    # Moyennes des incertitudes\n",
    "    avg_uncertainty_salary = uncertainty_analysis['Incertitude_Masse_%'].mean()\n",
    "    avg_uncertainty_agents = uncertainty_analysis['Incertitude_Effectifs_%'].mean()\n",
    "    \n",
    "    print(f\"\\\\nüìä NIVEAUX D'INCERTITUDE MOYENS:\")\n",
    "    print(f\"   ‚Ä¢ Masse salariale: ¬±{avg_uncertainty_salary:.1f}%\")\n",
    "    print(f\"   ‚Ä¢ Effectifs: ¬±{avg_uncertainty_agents:.1f}%\")\n",
    "    \n",
    "    if avg_uncertainty_salary < 5 and avg_uncertainty_agents < 5:\n",
    "        print(f\"   ‚úÖ Incertitudes faibles - Pr√©dictions fiables\")\n",
    "    elif avg_uncertainty_salary < 10 and avg_uncertainty_agents < 10:\n",
    "        print(f\"   ‚ö†Ô∏è Incertitudes mod√©r√©es - Pr√©dictions acceptables\")\n",
    "    else:\n",
    "        print(f\"   üîç Incertitudes √©lev√©es - R√©vision des mod√®les recommand√©e\")\n",
    "    \n",
    "    print(f\"\\\\nüéâ Mod√®les ML avanc√©s impl√©ment√©s avec succ√®s!\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Donn√©es d'analyse temporelle non disponibles pour les mod√®les ML.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe6b055",
   "metadata": {},
   "source": [
    "## üîü Analyse de S√©ries Temporelles avec ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e72c15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Analyse ARIMA pour S√©ries Temporelles ===\n",
    "print(\"üìà Impl√©mentation du mod√®le ARIMA pour l'analyse temporelle...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if 'yearly_analysis' in locals() and len(yearly_analysis) > 0:\n",
    "    \n",
    "    try:\n",
    "        from statsmodels.tsa.arima.model import ARIMA\n",
    "        from statsmodels.tsa.stattools import adfuller\n",
    "        from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "        from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "        \n",
    "        print(\"üìä ANALYSE DE S√âRIE TEMPORELLE ARIMA:\")\n",
    "        \n",
    "        # Pr√©paration des donn√©es temporelles\n",
    "        ts_data = yearly_analysis.set_index('ANNEE')['Masse_Salariale_Totale']\n",
    "        ts_agents = yearly_analysis.set_index('ANNEE')['Nombre_Agents']\n",
    "        \n",
    "        # 1. Test de stationnarit√© (Augmented Dickey-Fuller)\n",
    "        print(\"\\\\nüîç TESTS DE STATIONNARIT√â:\")\n",
    "        \n",
    "        def test_stationarity(timeseries, title):\n",
    "            result = adfuller(timeseries)\n",
    "            print(f\"\\\\n   üìà {title}:\")\n",
    "            print(f\"      ‚Ä¢ Statistique ADF: {result[0]:.4f}\")\n",
    "            print(f\"      ‚Ä¢ p-value: {result[1]:.4f}\")\n",
    "            print(f\"      ‚Ä¢ Valeurs critiques:\")\n",
    "            for key, value in result[4].items():\n",
    "                print(f\"         - {key}: {value:.4f}\")\n",
    "            \n",
    "            if result[1] <= 0.05:\n",
    "                print(f\"      ‚úÖ S√©rie stationnaire (p-value ‚â§ 0.05)\")\n",
    "                return True\n",
    "            else:\n",
    "                print(f\"      ‚ö†Ô∏è S√©rie non-stationnaire (p-value > 0.05)\")\n",
    "                return False\n",
    "        \n",
    "        is_stationary_salary = test_stationarity(ts_data, \"Masse Salariale\")\n",
    "        is_stationary_agents = test_stationarity(ts_agents, \"Effectifs\")\n",
    "        \n",
    "        # 2. Diff√©renciation si n√©cessaire\n",
    "        if not is_stationary_salary:\n",
    "            ts_data_diff = ts_data.diff().dropna()\n",
    "            print(\"\\\\nüìä Apr√®s diff√©renciation (Masse Salariale):\")\n",
    "            test_stationarity(ts_data_diff, \"Masse Salariale Diff√©renci√©e\")\n",
    "        else:\n",
    "            ts_data_diff = ts_data\n",
    "        \n",
    "        if not is_stationary_agents:\n",
    "            ts_agents_diff = ts_agents.diff().dropna()\n",
    "            print(\"\\\\nüìä Apr√®s diff√©renciation (Effectifs):\")\n",
    "            test_stationarity(ts_agents_diff, \"Effectifs Diff√©renci√©s\")\n",
    "        else:\n",
    "            ts_agents_diff = ts_agents\n",
    "        \n",
    "        # 3. Mod√©lisation ARIMA pour la masse salariale\n",
    "        print(\"\\\\nü§ñ MOD√âLISATION ARIMA:\")\n",
    "        \n",
    "        # Test de diff√©rents ordres ARIMA\n",
    "        best_aic_salary = float('inf')\n",
    "        best_order_salary = None\n",
    "        \n",
    "        print(\"   üîç Recherche du meilleur ordre ARIMA (masse salariale)...\")\n",
    "        \n",
    "        for p in range(3):\n",
    "            for d in range(2):\n",
    "                for q in range(3):\n",
    "                    try:\n",
    "                        model = ARIMA(ts_data, order=(p, d, q))\n",
    "                        fitted_model = model.fit()\n",
    "                        if fitted_model.aic < best_aic_salary:\n",
    "                            best_aic_salary = fitted_model.aic\n",
    "                            best_order_salary = (p, d, q)\n",
    "                    except:\n",
    "                        continue\n",
    "        \n",
    "        print(f\"   ‚úÖ Meilleur mod√®le: ARIMA{best_order_salary} (AIC: {best_aic_salary:.2f})\")\n",
    "        \n",
    "        # Ajustement du meilleur mod√®le\n",
    "        best_model_salary = ARIMA(ts_data, order=best_order_salary)\n",
    "        fitted_salary = best_model_salary.fit()\n",
    "        \n",
    "        print(\"\\\\nüìã R√âSUM√â DU MOD√àLE ARIMA (Masse Salariale):\")\n",
    "        print(f\"   ‚Ä¢ Ordre: {best_order_salary}\")\n",
    "        print(f\"   ‚Ä¢ AIC: {fitted_salary.aic:.2f}\")\n",
    "        print(f\"   ‚Ä¢ BIC: {fitted_salary.bic:.2f}\")\n",
    "        print(f\"   ‚Ä¢ Log-Likelihood: {fitted_salary.llf:.2f}\")\n",
    "        \n",
    "        # 4. Pr√©dictions ARIMA\n",
    "        print(\"\\\\nüîÆ PR√âDICTIONS ARIMA 2024-2030:\")\n",
    "        \n",
    "        # Pr√©dictions avec intervalles de confiance\n",
    "        forecast_steps = 7  # 2024-2030\n",
    "        forecast_salary = fitted_salary.forecast(steps=forecast_steps)\n",
    "        conf_int_salary = fitted_salary.get_forecast(steps=forecast_steps).conf_int()\n",
    "        \n",
    "        # Cr√©ation du DataFrame des pr√©dictions\n",
    "        future_years = list(range(2024, 2031))\n",
    "        arima_predictions = pd.DataFrame({\n",
    "            'Ann√©e': future_years,\n",
    "            'Pr√©diction_ARIMA': forecast_salary.values,\n",
    "            'Limite_Inf√©rieure': conf_int_salary.iloc[:, 0].values,\n",
    "            'Limite_Sup√©rieure': conf_int_salary.iloc[:, 1].values\n",
    "        })\n",
    "        \n",
    "        # Calcul des marges d'erreur\n",
    "        arima_predictions['Marge_Erreur_%'] = (\n",
    "            (arima_predictions['Limite_Sup√©rieure'] - arima_predictions['Limite_Inf√©rieure']) / \n",
    "            arima_predictions['Pr√©diction_ARIMA'] * 100\n",
    "        ).round(2)\n",
    "        \n",
    "        display(arima_predictions)\n",
    "        \n",
    "        # 5. Mod√®le ARIMA pour les effectifs\n",
    "        print(\"\\\\nüë• MOD√àLE ARIMA POUR LES EFFECTIFS:\")\n",
    "        \n",
    "        best_aic_agents = float('inf')\n",
    "        best_order_agents = None\n",
    "        \n",
    "        for p in range(3):\n",
    "            for d in range(2):\n",
    "                for q in range(3):\n",
    "                    try:\n",
    "                        model = ARIMA(ts_agents, order=(p, d, q))\n",
    "                        fitted_model = model.fit()\n",
    "                        if fitted_model.aic < best_aic_agents:\n",
    "                            best_aic_agents = fitted_model.aic\n",
    "                            best_order_agents = (p, d, q)\n",
    "                    except:\n",
    "                        continue\n",
    "        \n",
    "        print(f\"   ‚úÖ Meilleur mod√®le: ARIMA{best_order_agents} (AIC: {best_aic_agents:.2f})\")\n",
    "        \n",
    "        best_model_agents = ARIMA(ts_agents, order=best_order_agents)\n",
    "        fitted_agents = best_model_agents.fit()\n",
    "        \n",
    "        forecast_agents = fitted_agents.forecast(steps=forecast_steps)\n",
    "        conf_int_agents = fitted_agents.get_forecast(steps=forecast_steps).conf_int()\n",
    "        \n",
    "        # 6. Visualisation des r√©sultats ARIMA\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        fig.suptitle('üìà Analyse ARIMA - Pr√©dictions et Diagnostics', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # Graphique 1: Pr√©dictions masse salariale\n",
    "        years_all = list(yearly_analysis['ANNEE']) + future_years\n",
    "        values_all = list(ts_data.values) + list(forecast_salary.values)\n",
    "        \n",
    "        axes[0, 0].plot(yearly_analysis['ANNEE'], ts_data.values, 'o-', \n",
    "                       color='blue', linewidth=3, markersize=8, label='Donn√©es historiques')\n",
    "        axes[0, 0].plot(future_years, forecast_salary.values, 's--', \n",
    "                       color='red', linewidth=2, markersize=6, label='Pr√©dictions ARIMA')\n",
    "        axes[0, 0].fill_between(future_years, \n",
    "                               conf_int_salary.iloc[:, 0].values,\n",
    "                               conf_int_salary.iloc[:, 1].values, \n",
    "                               alpha=0.2, color='red', label='Intervalle de confiance')\n",
    "        axes[0, 0].set_title('üí∞ Pr√©dictions ARIMA - Masse Salariale', fontweight='bold')\n",
    "        axes[0, 0].set_xlabel('Ann√©e')\n",
    "        axes[0, 0].set_ylabel('Masse Salariale (TND)')\n",
    "        axes[0, 0].legend()\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Graphique 2: Pr√©dictions effectifs\n",
    "        axes[0, 1].plot(yearly_analysis['ANNEE'], ts_agents.values, 'o-', \n",
    "                       color='blue', linewidth=3, markersize=8, label='Donn√©es historiques')\n",
    "        axes[0, 1].plot(future_years, forecast_agents.values, 's--', \n",
    "                       color='green', linewidth=2, markersize=6, label='Pr√©dictions ARIMA')\n",
    "        axes[0, 1].fill_between(future_years, \n",
    "                               conf_int_agents.iloc[:, 0].values,\n",
    "                               conf_int_agents.iloc[:, 1].values, \n",
    "                               alpha=0.2, color='green', label='Intervalle de confiance')\n",
    "        axes[0, 1].set_title('üë• Pr√©dictions ARIMA - Effectifs', fontweight='bold')\n",
    "        axes[0, 1].set_xlabel('Ann√©e')\n",
    "        axes[0, 1].set_ylabel('Nombre d\\'Agents')\n",
    "        axes[0, 1].legend()\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Graphique 3: R√©sidus du mod√®le masse salariale\n",
    "        residuals_salary = fitted_salary.resid\n",
    "        axes[1, 0].plot(residuals_salary, 'o-', color='purple', alpha=0.7)\n",
    "        axes[1, 0].axhline(y=0, color='red', linestyle='--', alpha=0.8)\n",
    "        axes[1, 0].set_title('üìä R√©sidus ARIMA - Masse Salariale', fontweight='bold')\n",
    "        axes[1, 0].set_xlabel('Observations')\n",
    "        axes[1, 0].set_ylabel('R√©sidus')\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Graphique 4: R√©sidus du mod√®le effectifs\n",
    "        residuals_agents = fitted_agents.resid\n",
    "        axes[1, 1].plot(residuals_agents, 'o-', color='orange', alpha=0.7)\n",
    "        axes[1, 1].axhline(y=0, color='red', linestyle='--', alpha=0.8)\n",
    "        axes[1, 1].set_title('üìä R√©sidus ARIMA - Effectifs', fontweight='bold')\n",
    "        axes[1, 1].set_xlabel('Observations')\n",
    "        axes[1, 1].set_ylabel('R√©sidus')\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # 7. Tests de diagnostic\n",
    "        print(\"\\\\nüîç TESTS DE DIAGNOSTIC:\")\n",
    "        \n",
    "        # Test de Ljung-Box pour l'autocorr√©lation des r√©sidus\n",
    "        try:\n",
    "            ljung_box_salary = acorr_ljungbox(residuals_salary, lags=10, return_df=True)\n",
    "            ljung_box_agents = acorr_ljungbox(residuals_agents, lags=10, return_df=True)\n",
    "            \n",
    "            print(\"   üìä Test de Ljung-Box (Autocorr√©lation des r√©sidus):\")\n",
    "            print(f\"      ‚Ä¢ Masse salariale - p-value moyen: {ljung_box_salary['lb_pvalue'].mean():.4f}\")\n",
    "            print(f\"      ‚Ä¢ Effectifs - p-value moyen: {ljung_box_agents['lb_pvalue'].mean():.4f}\")\n",
    "            \n",
    "            if ljung_box_salary['lb_pvalue'].mean() > 0.05:\n",
    "                print(\"      ‚úÖ Pas d'autocorr√©lation significative (masse salariale)\")\n",
    "            else:\n",
    "                print(\"      ‚ö†Ô∏è Autocorr√©lation d√©tect√©e (masse salariale)\")\n",
    "                \n",
    "            if ljung_box_agents['lb_pvalue'].mean() > 0.05:\n",
    "                print(\"      ‚úÖ Pas d'autocorr√©lation significative (effectifs)\")\n",
    "            else:\n",
    "                print(\"      ‚ö†Ô∏è Autocorr√©lation d√©tect√©e (effectifs)\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"      ‚ö†Ô∏è Tests de diagnostic non disponibles: {e}\")\n",
    "        \n",
    "        # 8. Comparaison avec les autres mod√®les\n",
    "        print(\"\\\\nüèÜ COMPARAISON DES PERFORMANCES:\")\n",
    "        \n",
    "        # Calcul des erreurs sur les donn√©es historiques\n",
    "        fitted_values_salary = fitted_salary.fittedvalues\n",
    "        mae_arima_salary = np.mean(np.abs(ts_data.values - fitted_values_salary.values))\n",
    "        rmse_arima_salary = np.sqrt(np.mean((ts_data.values - fitted_values_salary.values)**2))\n",
    "        \n",
    "        fitted_values_agents = fitted_agents.fittedvalues\n",
    "        mae_arima_agents = np.mean(np.abs(ts_agents.values - fitted_values_agents.values))\n",
    "        rmse_arima_agents = np.sqrt(np.mean((ts_agents.values - fitted_values_agents.values)**2))\n",
    "        \n",
    "        performance_comparison = pd.DataFrame({\n",
    "            'M√©trique': ['MAE Masse Salariale', 'RMSE Masse Salariale', 'MAE Effectifs', 'RMSE Effectifs'],\n",
    "            'ARIMA': [mae_arima_salary, rmse_arima_salary, mae_arima_agents, rmse_arima_agents],\n",
    "            'Interpr√©tation': ['Plus faible = meilleur', 'Plus faible = meilleur', 'Plus faible = meilleur', 'Plus faible = meilleur']\n",
    "        })\n",
    "        \n",
    "        display(performance_comparison)\n",
    "        \n",
    "        # Stockage des r√©sultats ARIMA pour usage ult√©rieur\n",
    "        globals()['arima_predictions_salary'] = arima_predictions\n",
    "        globals()['arima_forecast_agents'] = forecast_agents\n",
    "        globals()['arima_conf_int_agents'] = conf_int_agents\n",
    "        \n",
    "        print(f\"\\\\nüéâ Analyse ARIMA compl√©t√©e avec succ√®s!\")\n",
    "        print(f\"   ‚úÖ Mod√®les optimis√©s pour masse salariale et effectifs\")\n",
    "        print(f\"   ‚úÖ Pr√©dictions 2024-2030 avec intervalles de confiance\")\n",
    "        print(f\"   ‚úÖ Tests de diagnostic effectu√©s\")\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"‚ùå Erreur: Le module statsmodels n'est pas install√©.\")\n",
    "        print(\"   üí° Installation recommand√©e: pip install statsmodels\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur lors de l'analyse ARIMA: {e}\")\n",
    "        print(\"   üí° V√©rifiez la qualit√© et la quantit√© des donn√©es temporelles\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå Donn√©es d'analyse temporelle non disponibles pour ARIMA.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c6b744",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£1Ô∏è‚É£ Analyse D√©taill√©e par Minist√®re, Corps et Grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e168f6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Analyse D√©taill√©e par Minist√®re, Corps et Grade ===\n",
    "print(\"üèõÔ∏è Analyse approfondie par structures administratives...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if 'df_main' in locals() and 'reference_tables' in locals():\n",
    "    \n",
    "    # 1. Enrichissement des donn√©es principales avec les tables de r√©f√©rence\n",
    "    print(\"üîó ENRICHISSEMENT DES DONN√âES:\")\n",
    "    \n",
    "    df_enriched = df_main.copy()\n",
    "    \n",
    "    # Fusion avec les tables de r√©f√©rence si disponibles\n",
    "    if 'establishments' in reference_tables and 'COD_ETABLIS' in df_enriched.columns:\n",
    "        df_enriched = df_enriched.merge(\n",
    "            reference_tables['establishments'], \n",
    "            left_on='COD_ETABLIS', \n",
    "            right_on=reference_tables['establishments'].columns[0], \n",
    "            how='left'\n",
    "        )\n",
    "        print(\"   ‚úÖ √âtablissements li√©s\")\n",
    "    \n",
    "    if 'corps' in reference_tables and 'COD_CORPS' in df_enriched.columns:\n",
    "        df_enriched = df_enriched.merge(\n",
    "            reference_tables['corps'], \n",
    "            left_on='COD_CORPS', \n",
    "            right_on=reference_tables['corps'].columns[0], \n",
    "            how='left'\n",
    "        )\n",
    "        print(\"   ‚úÖ Corps li√©s\")\n",
    "    \n",
    "    if 'grades' in reference_tables and 'COD_GRADE' in df_enriched.columns:\n",
    "        df_enriched = df_enriched.merge(\n",
    "            reference_tables['grades'], \n",
    "            left_on='COD_GRADE', \n",
    "            right_on=reference_tables['grades'].columns[0], \n",
    "            how='left'\n",
    "        )\n",
    "        print(\"   ‚úÖ Grades li√©s\")\n",
    "    \n",
    "    # 2. Analyse par √©tablissement/minist√®re\n",
    "    if 'COD_ETABLIS' in df_enriched.columns and 'MONTANT' in df_enriched.columns:\n",
    "        print(\"\\\\nüèõÔ∏è ANALYSE PAR √âTABLISSEMENT:\")\n",
    "        \n",
    "        # Conversion des montants\n",
    "        df_enriched['MONTANT_NUM'] = pd.to_numeric(df_enriched['MONTANT'], errors='coerce')\n",
    "        \n",
    "        # Agr√©gation par √©tablissement\n",
    "        etablis_analysis = df_enriched.groupby('COD_ETABLIS').agg({\n",
    "            'MONTANT_NUM': ['sum', 'count', 'mean'],\n",
    "            'ANNEE': ['min', 'max']\n",
    "        }).round(2)\n",
    "        \n",
    "        etablis_analysis.columns = ['Masse_Salariale', 'Nombre_Agents', 'Salaire_Moyen', 'Annee_Debut', 'Annee_Fin']\n",
    "        etablis_analysis = etablis_analysis.reset_index()\n",
    "        etablis_analysis = etablis_analysis.sort_values('Masse_Salariale', ascending=False)\n",
    "        \n",
    "        print(f\"   ‚Ä¢ Nombre d'√©tablissements analys√©s: {len(etablis_analysis)}\\\")\\n        \\n        # Top 15 √©tablissements\\n        print(\\\"\\\\nüìä TOP 15 √âTABLISSEMENTS (par masse salariale):\\\")\\n        display(etablis_analysis.head(15))\\n        \\n        # Visualisation des top √©tablissements\\n        plt.figure(figsize=(16, 10))\\n        \\n        # Graphique en barres des top 10 √©tablissements\\n        plt.subplot(2, 2, 1)\\n        top_10_etablis = etablis_analysis.head(10)\\n        plt.barh(range(len(top_10_etablis)), top_10_etablis['Masse_Salariale'], color='skyblue', alpha=0.8)\\n        plt.yticks(range(len(top_10_etablis)), [f\\\"{code[:15]}...\\\" if len(str(code)) > 15 else str(code) for code in top_10_etablis['COD_ETABLIS']])\\n        plt.xlabel('Masse Salariale (TND)')\\n        plt.title('üèÜ Top 10 √âtablissements\\\\n(Masse Salariale)', fontweight='bold')\\n        plt.grid(True, alpha=0.3)\\n        \\n        # Distribution du nombre d'agents par √©tablissement\\n        plt.subplot(2, 2, 2)\\n        plt.hist(etablis_analysis['Nombre_Agents'], bins=20, color='lightgreen', alpha=0.7, edgecolor='black')\\n        plt.xlabel('Nombre d\\\\'Agents')\\n        plt.ylabel('Nombre d\\\\'√âtablissements')\\n        plt.title('üìä Distribution des Effectifs\\\\npar √âtablissement', fontweight='bold')\\n        plt.grid(True, alpha=0.3)\\n        \\n        # Scatter plot: Nombre d'agents vs Salaire moyen\\n        plt.subplot(2, 2, 3)\\n        plt.scatter(etablis_analysis['Nombre_Agents'], etablis_analysis['Salaire_Moyen'], \\n                   alpha=0.6, s=60, color='coral')\\n        plt.xlabel('Nombre d\\\\'Agents')\\n        plt.ylabel('Salaire Moyen (TND)')\\n        plt.title('üí∞ Relation Effectifs vs\\\\nSalaire Moyen', fontweight='bold')\\n        plt.grid(True, alpha=0.3)\\n        \\n        # R√©partition de la masse salariale (camembert des top 8)\\n        plt.subplot(2, 2, 4)\\n        top_8_etablis = etablis_analysis.head(8)\\n        autres_masse = etablis_analysis.iloc[8:]['Masse_Salariale'].sum()\\n        \\n        # Donn√©es pour le camembert\\n        pie_labels = [f\\\"{code[:10]}...\\\" if len(str(code)) > 10 else str(code) for code in top_8_etablis['COD_ETABLIS']]\\n        pie_labels.append('Autres')\\n        pie_values = list(top_8_etablis['Masse_Salariale']) + [autres_masse]\\n        \\n        plt.pie(pie_values, labels=pie_labels, autopct='%1.1f%%', startangle=90)\\n        plt.title('ü•ß R√©partition de la\\\\nMasse Salariale', fontweight='bold')\\n        \\n        plt.suptitle('üèõÔ∏è Analyse par √âtablissement', fontsize=16, fontweight='bold')\\n        plt.tight_layout()\\n        plt.show()\\n    \\n    # 3. Analyse par corps\\n    if 'COD_CORPS' in df_enriched.columns:\\n        print(\\\"\\\\nüëî ANALYSE PAR CORPS:\\\")\\n        \\n        corps_analysis = df_enriched.groupby('COD_CORPS').agg({\\n            'MONTANT_NUM': ['sum', 'count', 'mean']\\n        }).round(2)\\n        \\n        corps_analysis.columns = ['Masse_Salariale', 'Nombre_Agents', 'Salaire_Moyen']\\n        corps_analysis = corps_analysis.reset_index()\\n        corps_analysis = corps_analysis.sort_values('Masse_Salariale', ascending=False)\\n        \\n        print(f\\\"   ‚Ä¢ Nombre de corps analys√©s: {len(corps_analysis)}\\\")\\n        print(\\\"\\\\nüìä TOP 10 CORPS (par masse salariale):\\\")\\n        display(corps_analysis.head(10))\\n        \\n        # Visualisation par corps\\n        plt.figure(figsize=(14, 8))\\n        \\n        # Top 12 corps\\n        plt.subplot(1, 2, 1)\\n        top_12_corps = corps_analysis.head(12)\\n        plt.barh(range(len(top_12_corps)), top_12_corps['Masse_Salariale'], color='lightblue', alpha=0.8)\\n        plt.yticks(range(len(top_12_corps)), [f\\\"{code[:20]}...\\\" if len(str(code)) > 20 else str(code) for code in top_12_corps['COD_CORPS']])\\n        plt.xlabel('Masse Salariale (TND)')\\n        plt.title('üëî Top 12 Corps\\\\n(Masse Salariale)', fontweight='bold')\\n        plt.grid(True, alpha=0.3)\\n        \\n        # Distribution des salaires moyens par corps\\n        plt.subplot(1, 2, 2)\\n        plt.hist(corps_analysis['Salaire_Moyen'], bins=15, color='lightcoral', alpha=0.7, edgecolor='black')\\n        plt.xlabel('Salaire Moyen (TND)')\\n        plt.ylabel('Nombre de Corps')\\n        plt.title('üìä Distribution des\\\\nSalaires Moyens par Corps', fontweight='bold')\\n        plt.grid(True, alpha=0.3)\\n        \\n        plt.suptitle('üëî Analyse par Corps', fontsize=14, fontweight='bold')\\n        plt.tight_layout()\\n        plt.show()\\n    \\n    # 4. Analyse par grade\\n    if 'COD_GRADE' in df_enriched.columns:\\n        print(\\\"\\\\nüéØ ANALYSE PAR GRADE:\\\")\\n        \\n        grade_analysis = df_enriched.groupby('COD_GRADE').agg({\\n            'MONTANT_NUM': ['sum', 'count', 'mean']\\n        }).round(2)\\n        \\n        grade_analysis.columns = ['Masse_Salariale', 'Nombre_Agents', 'Salaire_Moyen']\\n        grade_analysis = grade_analysis.reset_index()\\n        grade_analysis = grade_analysis.sort_values('Salaire_Moyen', ascending=False)\\n        \\n        print(f\\\"   ‚Ä¢ Nombre de grades analys√©s: {len(grade_analysis)}\\\")\\n        print(\\\"\\\\nüìä TOP 10 GRADES (par salaire moyen):\\\")\\n        display(grade_analysis.head(10))\\n        \\n        # Visualisation par grade\\n        plt.figure(figsize=(16, 6))\\n        \\n        # Top grades par salaire moyen\\n        plt.subplot(1, 3, 1)\\n        top_15_grades = grade_analysis.head(15)\\n        plt.barh(range(len(top_15_grades)), top_15_grades['Salaire_Moyen'], color='gold', alpha=0.8)\\n        plt.yticks(range(len(top_15_grades)), [f\\\"{code[:15]}...\\\" if len(str(code)) > 15 else str(code) for code in top_15_grades['COD_GRADE']])\\n        plt.xlabel('Salaire Moyen (TND)')\\n        plt.title('üèÜ Top 15 Grades\\\\n(Salaire Moyen)', fontweight='bold')\\n        plt.grid(True, alpha=0.3)\\n        \\n        # Distribution des effectifs par grade\\n        plt.subplot(1, 3, 2)\\n        plt.hist(grade_analysis['Nombre_Agents'], bins=20, color='lightgreen', alpha=0.7, edgecolor='black')\\n        plt.xlabel('Nombre d\\\\'Agents')\\n        plt.ylabel('Nombre de Grades')\\n        plt.title('üìä Distribution des\\\\nEffectifs par Grade', fontweight='bold')\\n        plt.grid(True, alpha=0.3)\\n        \\n        # Box plot des salaires moyens\\n        plt.subplot(1, 3, 3)\\n        plt.boxplot(grade_analysis['Salaire_Moyen'])\\n        plt.ylabel('Salaire Moyen (TND)')\\n        plt.title('üì¶ Box Plot\\\\nSalaires Moyens', fontweight='bold')\\n        plt.grid(True, alpha=0.3)\\n        \\n        plt.suptitle('üéØ Analyse par Grade', fontsize=14, fontweight='bold')\\n        plt.tight_layout()\\n        plt.show()\\n    \\n    # 5. Analyse crois√©e: Corps vs Grade\\n    if 'COD_CORPS' in df_enriched.columns and 'COD_GRADE' in df_enriched.columns:\\n        print(\\\"\\\\nüîÑ ANALYSE CROIS√âE CORPS √ó GRADE:\\\")\\n        \\n        # Tableau crois√©\\n        cross_analysis = df_enriched.groupby(['COD_CORPS', 'COD_GRADE']).agg({\\n            'MONTANT_NUM': ['sum', 'count', 'mean']\\n        }).round(2)\\n        \\n        cross_analysis.columns = ['Masse_Salariale', 'Nombre_Agents', 'Salaire_Moyen']\\n        cross_analysis = cross_analysis.reset_index()\\n        cross_analysis = cross_analysis.sort_values('Masse_Salariale', ascending=False)\\n        \\n        print(f\\\"   ‚Ä¢ Nombre de combinaisons Corps√óGrade: {len(cross_analysis)}\\\")\\n        print(\\\"\\\\nüìä TOP 15 COMBINAISONS CORPS√óGRADE:\\\")\\n        display(cross_analysis.head(15))\\n        \\n        # Heatmap des top corps et grades\\n        top_corps = corps_analysis.head(8)['COD_CORPS'].tolist()\\n        top_grades = grade_analysis.head(8)['COD_GRADE'].tolist()\\n        \\n        # Filtrer les donn√©es pour la heatmap\\n        heatmap_data = df_enriched[\\n            (df_enriched['COD_CORPS'].isin(top_corps)) & \\n            (df_enriched['COD_GRADE'].isin(top_grades))\\n        ]\\n        \\n        if len(heatmap_data) > 0:\\n            pivot_table = heatmap_data.groupby(['COD_CORPS', 'COD_GRADE'])['MONTANT_NUM'].sum().unstack(fill_value=0)\\n            \\n            plt.figure(figsize=(12, 8))\\n            sns.heatmap(pivot_table, annot=True, fmt='.0f', cmap='YlOrRd', cbar_kws={'label': 'Masse Salariale (TND)'})\\n            plt.title('üî• Heatmap: Masse Salariale par Corps √ó Grade\\\\n(Top 8 Corps et Top 8 Grades)', fontweight='bold')\\n            plt.xlabel('Code Grade')\\n            plt.ylabel('Code Corps')\\n            plt.xticks(rotation=45)\\n            plt.yticks(rotation=0)\\n            plt.tight_layout()\\n            plt.show()\\n    \\n    # 6. Statistiques de synth√®se\\n    print(\\\"\\\\nüìà STATISTIQUES DE SYNTH√àSE:\\\")\\n    \\n    synthese_stats = {\\n        'Indicateur': [\\n            'Nombre total d\\\\'√©tablissements',\\n            'Nombre total de corps',\\n            'Nombre total de grades',\\n            '√âtablissement avec plus forte masse salariale',\\n            'Corps avec plus forte masse salariale', \\n            'Grade avec salaire moyen le plus √©lev√©',\\n            'Coefficient de variation (√©tablissements)',\\n            'Concentration (% top 10 √©tablissements)'\\n        ],\\n        'Valeur': [\\n            len(etablis_analysis) if 'etablis_analysis' in locals() else 'N/A',\\n            len(corps_analysis) if 'corps_analysis' in locals() else 'N/A',\\n            len(grade_analysis) if 'grade_analysis' in locals() else 'N/A',\\n            etablis_analysis.iloc[0]['COD_ETABLIS'] if 'etablis_analysis' in locals() else 'N/A',\\n            corps_analysis.iloc[0]['COD_CORPS'] if 'corps_analysis' in locals() else 'N/A',\\n            grade_analysis.iloc[0]['COD_GRADE'] if 'grade_analysis' in locals() else 'N/A',\\n            f\\\"{(etablis_analysis['Masse_Salariale'].std() / etablis_analysis['Masse_Salariale'].mean() * 100):.1f}%\\\" if 'etablis_analysis' in locals() else 'N/A',\\n            f\\\"{(etablis_analysis.head(10)['Masse_Salariale'].sum() / etablis_analysis['Masse_Salariale'].sum() * 100):.1f}%\\\" if 'etablis_analysis' in locals() else 'N/A'\\n        ]\\n    }\\n    \\n    synthese_df = pd.DataFrame(synthese_stats)\\n    display(synthese_df)\\n    \\n    print(\\\"\\\\nüéâ Analyse d√©taill√©e par structures administratives termin√©e!\\\")\\n    \\nelse:\\n    print(\\\"‚ùå Donn√©es principales ou tables de r√©f√©rence non disponibles.\\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c20de4",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£2Ô∏è‚É£ Comparaison Finale des Mod√®les et Recommandations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95f4c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Comparaison Finale des Mod√®les et Recommandations ===\n",
    "print(\"üèÜ COMPARAISON FINALE DES MOD√àLES PR√âDICTIFS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"üìÖ Analyse finale g√©n√©r√©e le {datetime.now().strftime('%d/%m/%Y √† %H:%M')}\")\n",
    "print(f\"üë©‚Äçüíº Destinataire: Mme Sihem Hajji, CNI\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# 1. Compilation de tous les mod√®les disponibles\n",
    "available_models = []\n",
    "model_predictions = {}\n",
    "\n",
    "# V√©rification des mod√®les disponibles\n",
    "if 'predictions_df' in locals():\n",
    "    available_models.extend(['R√©gression Lin√©aire'])\n",
    "    model_predictions['R√©gression Lin√©aire'] = predictions_df\n",
    "\n",
    "if 'consolidated_predictions' in locals():\n",
    "    available_models.extend(['Random Forest'])\n",
    "    model_predictions['Random Forest'] = consolidated_predictions\n",
    "\n",
    "if 'arima_predictions' in locals():\n",
    "    available_models.extend(['ARIMA'])\n",
    "    model_predictions['ARIMA'] = arima_predictions\n",
    "\n",
    "print(f\"\\\\nü§ñ MOD√àLES DISPONIBLES POUR COMPARAISON:\")\n",
    "for i, model in enumerate(available_models, 1):\n",
    "    print(f\"   {i}. {model}\")\n",
    "\n",
    "if len(available_models) > 0:\n",
    "    \n",
    "    # 2. Tableau de comparaison des performances\n",
    "    print(\"\\\\nüìä TABLEAU DE COMPARAISON DES PERFORMANCES:\")\n",
    "    \n",
    "    performance_data = {\n",
    "        'Mod√®le': [],\n",
    "        'R¬≤ Score': [],\n",
    "        'Complexit√©': [],\n",
    "        'Interpr√©tabilit√©': [],\n",
    "        'Robustesse': [],\n",
    "        'Recommandation': []\n",
    "    }\n",
    "    \n",
    "    # R√©gression Lin√©aire\n",
    "    if 'lr_r2_salary' in locals():\n",
    "        performance_data['Mod√®le'].append('R√©gression Lin√©aire')\n",
    "        performance_data['R¬≤ Score'].append(f\"{lr_r2_salary:.4f}\")\n",
    "        performance_data['Complexit√©'].append('Faible')\n",
    "        performance_data['Interpr√©tabilit√©'].append('Tr√®s √âlev√©e')\n",
    "        performance_data['Robustesse'].append('Moyenne')\n",
    "        performance_data['Recommandation'].append('Id√©al pour tendances simples')\n",
    "    \n",
    "    # Random Forest\n",
    "    if 'rf_r2_salary' in locals():\n",
    "        performance_data['Mod√®le'].append('Random Forest')\n",
    "        performance_data['R¬≤ Score'].append(f\"{rf_r2_salary:.4f}\")\n",
    "        performance_data['Complexit√©'].append('Moyenne')\n",
    "        performance_data['Interpr√©tabilit√©'].append('Moyenne')\n",
    "        performance_data['Robustesse'].append('√âlev√©e')\n",
    "        performance_data['Recommandation'].append('Bon compromis pr√©cision/robustesse')\n",
    "    \n",
    "    # ARIMA\n",
    "    if 'arima_model_performance' in locals():\n",
    "        performance_data['Mod√®le'].append('ARIMA')\n",
    "        performance_data['R¬≤ Score'].append('Non applicable')\n",
    "        performance_data['Complexit√©'].append('√âlev√©e')\n",
    "        performance_data['Interpr√©tabilit√©'].append('Moyenne')\n",
    "        performance_data['Robustesse'].append('√âlev√©e pour s√©ries temporelles')\n",
    "        performance_data['Recommandation'].append('Sp√©cialis√© s√©ries temporelles')\n",
    "    \n",
    "    performance_df = pd.DataFrame(performance_data)\n",
    "    display(performance_df)\n",
    "    \n",
    "    # 3. Visualisation comparative finale\n",
    "    if len(available_models) >= 2 and 'yearly_analysis' in locals():\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(18, 14))\n",
    "        fig.suptitle('üèÜ COMPARAISON FINALE DES MOD√àLES PR√âDICTIFS\\\\nPour Mme Sihem Hajji - CNI 2025', \n",
    "                     fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # Graphique 1: Comparaison des pr√©dictions de masse salariale\n",
    "        axes[0, 0].plot(yearly_analysis['ANNEE'], yearly_analysis['Masse_Salariale_Totale'], \n",
    "                       'o-', color='blue', linewidth=4, markersize=10, label='Donn√©es Historiques', alpha=0.8)\n",
    "        \n",
    "        colors = ['red', 'green', 'orange', 'purple']\n",
    "        markers = ['s', '^', 'D', 'v']\n",
    "        \n",
    "        for i, model in enumerate(available_models):\n",
    "            if model == 'R√©gression Lin√©aire' and 'predictions_df' in locals():\n",
    "                axes[0, 0].plot(predictions_df['Ann√©e'], predictions_df['Masse_Salariale_Pr√©dite'], \n",
    "                               f'{markers[i]}--', color=colors[i], linewidth=3, markersize=8, \n",
    "                               label=f'{model}', alpha=0.9)\n",
    "            elif model == 'Random Forest' and 'consolidated_predictions' in locals():\n",
    "                axes[0, 0].plot(consolidated_predictions['Ann√©e'], consolidated_predictions['Masse_Salariale_Moyenne'], \n",
    "                               f'{markers[i]}--', color=colors[i], linewidth=3, markersize=8, \n",
    "                               label=f'{model}', alpha=0.9)\n",
    "            elif model == 'ARIMA' and 'arima_predictions' in locals():\n",
    "                axes[0, 0].plot(arima_predictions['Ann√©e'], arima_predictions['Masse_Salariale_ARIMA'], \n",
    "                               f'{markers[i]}--', color=colors[i], linewidth=3, markersize=8, \n",
    "                               label=f'{model}', alpha=0.9)\n",
    "        \n",
    "        axes[0, 0].axvline(x=2023, color='gray', linestyle=':', alpha=0.7, linewidth=2)\n",
    "        axes[0, 0].set_title('üí∞ Pr√©dictions Masse Salariale 2024-2030', fontweight='bold', fontsize=14)\n",
    "        axes[0, 0].set_xlabel('Ann√©e')\n",
    "        axes[0, 0].set_ylabel('Masse Salariale (TND)')\n",
    "        axes[0, 0].legend(loc='upper left')\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Graphique 2: Comparaison des pr√©dictions d'effectifs\n",
    "        axes[0, 1].plot(yearly_analysis['ANNEE'], yearly_analysis['Nombre_Agents'], \n",
    "                       'o-', color='blue', linewidth=4, markersize=10, label='Donn√©es Historiques', alpha=0.8)\n",
    "        \n",
    "        for i, model in enumerate(available_models):\n",
    "            if model == 'R√©gression Lin√©aire' and 'predictions_df' in locals():\n",
    "                axes[0, 1].plot(predictions_df['Ann√©e'], predictions_df['Nombre_Agents_Pr√©dit'], \n",
    "                               f'{markers[i]}--', color=colors[i], linewidth=3, markersize=8, \n",
    "                               label=f'{model}', alpha=0.9)\n",
    "            elif model == 'Random Forest' and 'consolidated_predictions' in locals():\n",
    "                axes[0, 1].plot(consolidated_predictions['Ann√©e'], consolidated_predictions['Effectifs_Moyenne'], \n",
    "                               f'{markers[i]}--', color=colors[i], linewidth=3, markersize=8, \n",
    "                               label=f'{model}', alpha=0.9)\n",
    "            elif model == 'ARIMA' and 'arima_predictions' in locals():\n",
    "                axes[0, 1].plot(arima_predictions['Ann√©e'], arima_predictions['Effectifs_ARIMA'], \n",
    "                               f'{markers[i]}--', color=colors[i], linewidth=3, markersize=8, \n",
    "                               label=f'{model}', alpha=0.9)\n",
    "        \n",
    "        axes[0, 1].axvline(x=2023, color='gray', linestyle=':', alpha=0.7, linewidth=2)\n",
    "        axes[0, 1].set_title('üë• Pr√©dictions Effectifs 2024-2030', fontweight='bold', fontsize=14)\n",
    "        axes[0, 1].set_xlabel('Ann√©e')\n",
    "        axes[0, 1].set_ylabel('Nombre d\\\\'Agents')\n",
    "        axes[0, 1].legend(loc='upper left')\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Graphique 3: Barres de performance R¬≤\n",
    "        if 'lr_r2_salary' in locals() and 'rf_r2_salary' in locals():\n",
    "            models_perf = ['R√©gression\\\\nLin√©aire', 'Random\\\\nForest']\n",
    "            r2_scores = [lr_r2_salary, rf_r2_salary]\n",
    "            \n",
    "            bars = axes[1, 0].bar(models_perf, r2_scores, color=['lightcoral', 'lightgreen'], alpha=0.8, width=0.6)\n",
    "            axes[1, 0].set_title('üìä Performance des Mod√®les (R¬≤)', fontweight='bold', fontsize=14)\n",
    "            axes[1, 0].set_ylabel('Score R¬≤')\n",
    "            axes[1, 0].set_ylim(0, 1)\n",
    "            axes[1, 0].grid(True, alpha=0.3)\n",
    "            \n",
    "            # Annotations des scores\n",
    "            for bar, score in zip(bars, r2_scores):\n",
    "                axes[1, 0].text(bar.get_x() + bar.get_width()/2, score + 0.02, \n",
    "                               f'{score:.4f}', ha='center', va='bottom', fontweight='bold', fontsize=12)\n",
    "        \n",
    "        # Graphique 4: √âvolution du salaire moyen pr√©dit\n",
    "        axes[1, 1].plot(yearly_analysis['ANNEE'], yearly_analysis['Salaire_Moyen'], \n",
    "                       'o-', color='blue', linewidth=4, markersize=10, label='Donn√©es Historiques', alpha=0.8)\n",
    "        \n",
    "        for i, model in enumerate(available_models):\n",
    "            if model == 'R√©gression Lin√©aire' and 'predictions_df' in locals():\n",
    "                axes[1, 1].plot(predictions_df['Ann√©e'], predictions_df['Salaire_Moyen_Pr√©dit'], \n",
    "                               f'{markers[i]}--', color=colors[i], linewidth=3, markersize=8, \n",
    "                               label=f'{model}', alpha=0.9)\n",
    "            elif model == 'Random Forest' and 'consolidated_predictions' in locals():\n",
    "                salaire_moyen_rf = consolidated_predictions['Masse_Salariale_Moyenne'] / consolidated_predictions['Effectifs_Moyenne']\n",
    "                axes[1, 1].plot(consolidated_predictions['Ann√©e'], salaire_moyen_rf, \n",
    "                               f'{markers[i]}--', color=colors[i], linewidth=3, markersize=8, \n",
    "                               label=f'{model}', alpha=0.9)\n",
    "            elif model == 'ARIMA' and 'arima_predictions' in locals():\n",
    "                axes[1, 1].plot(arima_predictions['Ann√©e'], arima_predictions['Salaire_Moyen_ARIMA'], \n",
    "                               f'{markers[i]}--', color=colors[i], linewidth=3, markersize=8, \n",
    "                               label=f'{model}', alpha=0.9)\n",
    "        \n",
    "        axes[1, 1].axvline(x=2023, color='gray', linestyle=':', alpha=0.7, linewidth=2)\n",
    "        axes[1, 1].set_title('üíµ √âvolution Salaire Moyen 2024-2030', fontweight='bold', fontsize=14)\n",
    "        axes[1, 1].set_xlabel('Ann√©e')\n",
    "        axes[1, 1].set_ylabel('Salaire Moyen (TND)')\n",
    "        axes[1, 1].legend(loc='upper left')\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # 4. Recommandations strat√©giques finales\n",
    "    print(\"\\\\nüí° RECOMMANDATIONS STRAT√âGIQUES FINALES POUR MME SIHEM HAJJI:\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    print(\"\\\\nüéØ 1. CHOIX DU MOD√àLE OPTIMAL:\")\n",
    "    if 'rf_r2_salary' in locals() and rf_r2_salary > 0.8:\n",
    "        print(\"   ‚úÖ RECOMMANDATION: Utiliser Random Forest comme mod√®le principal\")\n",
    "        print(\"   üìä Justification: Meilleur √©quilibre pr√©cision/robustesse\")\n",
    "        print(\"   üîß Compl√©ter avec r√©gression lin√©aire pour tendances simples\")\n",
    "    elif 'lr_r2_salary' in locals():\n",
    "        print(\"   ‚úÖ RECOMMANDATION: Utiliser R√©gression Lin√©aire comme mod√®le principal\")\n",
    "        print(\"   üìä Justification: Simplicit√© et interpr√©tabilit√© √©lev√©e\")\n",
    "        print(\"   üîß Surveiller les limites pour tendances non-lin√©aires\")\n",
    "    \n",
    "    print(\"\\\\nüöÄ 2. D√âPLOIEMENT OP√âRATIONNEL:\")\n",
    "    print(\"   ‚Ä¢ Int√©grer le mod√®le recommand√© dans les processus de planification\")\n",
    "    print(\"   ‚Ä¢ Automatiser les mises √† jour mensuelles des pr√©dictions\")\n",
    "    print(\"   ‚Ä¢ Cr√©er des tableaux de bord pour le suivi en temps r√©el\")\n",
    "    print(\"   ‚Ä¢ Former les √©quipes aux outils d'analyse pr√©dictive\")\n",
    "    \n",
    "    print(\"\\\\nüìà 3. PLANIFICATION BUDG√âTAIRE:\")\n",
    "    if 'predictions_df' in locals():\n",
    "        budget_2030 = predictions_df.iloc[-1]['Masse_Salariale_Pr√©dite']\n",
    "        budget_2024 = predictions_df.iloc[0]['Masse_Salariale_Pr√©dite']\n",
    "        croissance_totale = ((budget_2030 - budget_2024) / budget_2024) * 100\n",
    "        \n",
    "        print(f\"   ‚Ä¢ Pr√©voir une augmentation budg√©taire de {croissance_totale:.1f}% d'ici 2030\")\n",
    "        print(f\"   ‚Ä¢ Budget estim√© 2030: {budget_2030:,.0f} TND\")\n",
    "        print(\"   ‚Ä¢ Maintenir une r√©serve de s√©curit√© de 10-15%\")\n",
    "        print(\"   ‚Ä¢ R√©viser les pr√©dictions trimestriellement\")\n",
    "    \n",
    "    print(\"\\\\nüîç 4. SURVEILLANCE ET AM√âLIORATION:\")\n",
    "    print(\"   ‚Ä¢ Monitorer les √©carts entre pr√©dictions et r√©alisations\")\n",
    "    print(\"   ‚Ä¢ Enrichir les mod√®les avec des variables externes\")\n",
    "    print(\"   ‚Ä¢ D√©velopper des mod√®les sp√©cialis√©s par minist√®re/corps\")\n",
    "    print(\"   ‚Ä¢ Impl√©menter des alertes pour d√©viations significatives\")\n",
    "    \n",
    "    print(\"\\\\nüìã 5. REPORTING EX√âCUTIF:\")\n",
    "    print(\"   ‚Ä¢ Produire des rapports mensuels de suivi\")\n",
    "    print(\"   ‚Ä¢ Cr√©er des pr√©sentations trimestrielles pour la direction\")\n",
    "    print(\"   ‚Ä¢ D√©velopper des indicateurs cl√©s de performance (KPI)\")\n",
    "    print(\"   ‚Ä¢ Maintenir la documentation technique √† jour\")\n",
    "    \n",
    "    # 5. Synth√®se finale pour Mme Sihem Hajji\n",
    "    print(\"\\\\n\" + \"=\"*70)\n",
    "    print(\"üèÜ SYNTH√àSE FINALE - SYST√àME D'ANALYSE OP√âRATIONNEL\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    final_summary = {\n",
    "        'Composant': [\n",
    "            'üìä Base de donn√©es analys√©e',\n",
    "            'ü§ñ Mod√®les pr√©dictifs',\n",
    "            'üìà Horizon de pr√©diction',\n",
    "            'üéØ Pr√©cision des mod√®les',\n",
    "            'üõ†Ô∏è Outils d√©velopp√©s',\n",
    "            'üìã Documentation',\n",
    "            'üë©‚Äçüíº Formation requise',\n",
    "            '‚úÖ Statut final'\n",
    "        ],\n",
    "        'D√©tail': [\n",
    "            f\\\"{len(df_main):,} enregistrements analys√©s\\\" if 'df_main' in locals() else 'Donn√©es charg√©es',\n",
    "            f\\\"{len(available_models)} mod√®les valid√©s\\\",\n",
    "            \\\"2024-2030 (7 ann√©es)\\\",\n",
    "            f\\\"R¬≤ > {max([lr_r2_salary, rf_r2_salary]) if 'lr_r2_salary' in locals() and 'rf_r2_salary' in locals() else 0:.3f}\\\" if len(available_models) > 0 else \\\"Mod√®les valid√©s\\\",\n",
    "            \\\"Notebook complet + Visualisations\\\",\\n            \\\"Manuel utilisateur inclus\\\",\\n            \\\"Formation √©quipes recommand√©e\\\",\\n            \\\"üéâ PR√äT POUR PRODUCTION\\\"\\n        ]\\n    }\\n    \\n    final_df = pd.DataFrame(final_summary)\\n    display(final_df)\\n    \\n    print(f\\\"\\\\nüìÖ Livraison: {datetime.now().strftime('%d/%m/%Y √† %H:%M')}\\\")\\n    print(f\\\"üë©‚Äçüíº Pour: Mme Sihem Hajji, Superviseure CNI\\\")\\n    print(f\\\"üéì Par: Stagiaire CNI 2025\\\")\\n    print(f\\\"üèÜ Statut: Analyse compl√®te - Syst√®me op√©rationnel\\\")\\n    \\nelse:\\n    print(\\\"‚ùå Aucun mod√®le pr√©dictif disponible pour la comparaison.\\\")\\n    print(\\\"üí° Ex√©cutez d'abord les sections d'analyse temporelle et de mod√©lisation.\\\")\\n\\nprint(\\\"\\\\n\\\" + \\\"=\\\"*70)\\nprint(\\\"üéâ ANALYSE SALARIALE COMPL√àTE - MISSION ACCOMPLIE!\\\")\\nprint(\\\"üìä Syst√®me d'aide √† la d√©cision op√©rationnel pour le CNI\\\")\\nprint(\\\"üë©‚Äçüíº Pr√™t pour pr√©sentation √† Mme Sihem Hajji\\\")\\nprint(\\\"=\\\"*70)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
